{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5fa9d8d-e0f2-477e-a277-deb91814cb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive Bayes\n",
      "Accuracy Score: 98.91618497109826%\n",
      "Confusion Matrix: \n",
      "[[586  12]\n",
      " [  3 783]]\n",
      "\n",
      "Logistic Regression\n",
      "Accuracy Score: 99.34971098265896%\n",
      "Confusion Matrix: \n",
      "[[593   5]\n",
      " [  4 782]]\n",
      "\n",
      "Support Vector Machine\n",
      "Accuracy Score: 99.0606936416185%\n",
      "Confusion Matrix: \n",
      "[[592   6]\n",
      " [  7 779]]\n",
      "\n",
      "K Nearest Neighbors (NN = 3)\n",
      "Accuracy Score: 98.69942196531792%\n",
      "Confusion Matrix: \n",
      "[[589   9]\n",
      " [  9 777]]\n",
      "\n",
      "Analysis\n",
      "No. of tokens:  294\n",
      "No. of positive tokens:  143\n",
      "No. of negative tokens:  151\n",
      "\n",
      "Search Results for token/s: ['awesome']\n",
      "      Token  Positive  Negative\n",
      "11  awesome     896.0       1.0\n",
      "3001    yeah i know the two movies are of different ge...\n",
      "1172     today was so cool and mission impossible rocked.\n",
      "1185    Think Mission Impossible, think Bond Girls, th...\n",
      "1162    mission impossible did kick ass and yes jessic...\n",
      "1122    Mission impossible was pretty cool, though I w...\n",
      "2998        I did kinda like Brokeback Mountain though...\n",
      "2992    no, I hope this doesn't end up like Brokeback ...\n",
      "2991    and i wanna shout out a big fat thank you to e...\n",
      "2993        gosh i miss telling Brokeback Mountain news!.\n",
      "Name: Review, dtype: object\n",
      "5032                     And Harry Potter looks stupid:..\n",
      "5107     I could hate Harry Potter, but love his scent...\n",
      "4038    i hated the da vinci code, the movie witha pas...\n",
      "3953    If Jesus is fabricated a la the Da Vinci Code ...\n",
      "5109    I loathe Harry Potter, Lord of the Rings and a...\n",
      "5035    I am SOOOOOO sick of people claiming that Harr...\n",
      "3945    i thought the da vinci code movie was really b...\n",
      "5038    Wiccans react to possible Harry Potter book ba...\n",
      "5050    Marcia Gaither, who teaches classes in Wiccani...\n",
      "Name: Review, dtype: object\n",
      "\n",
      "Test a custom review message\n",
      "Enter review to be analysed:  "
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " it a bad movie\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The review is predicted Negative\n"
     ]
    }
   ],
   "source": [
    "#Importing Essentials\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "path = 'opinions.tsv'\n",
    "data = pd.read_table(path,header=None,skiprows=1,names=['Sentiment','Review'])\n",
    "X = data.Review\n",
    "y = data.Sentiment\n",
    "#Using CountVectorizer to convert text into tokens/features\n",
    "vect = CountVectorizer(stop_words='english', ngram_range = (1,1), max_df = .80, min_df = 4)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=1, test_size= 0.2)\n",
    "#Using training data to transform text into counts of features for each message\n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train) \n",
    "X_test_dtm = vect.transform(X_test)\n",
    "\n",
    "#Accuracy using Naive Bayes Model\n",
    "NB = MultinomialNB()\n",
    "NB.fit(X_train_dtm, y_train)\n",
    "y_pred = NB.predict(X_test_dtm)\n",
    "print('\\nNaive Bayes')\n",
    "print('Accuracy Score: ',metrics.accuracy_score(y_test,y_pred)*100,'%',sep='')\n",
    "print('Confusion Matrix: ',metrics.confusion_matrix(y_test,y_pred), sep = '\\n')\n",
    "\n",
    "#Accuracy using Logistic Regression Model\n",
    "LR = LogisticRegression()\n",
    "LR.fit(X_train_dtm, y_train)\n",
    "y_pred = LR.predict(X_test_dtm)\n",
    "print('\\nLogistic Regression')\n",
    "print('Accuracy Score: ',metrics.accuracy_score(y_test,y_pred)*100,'%',sep='')\n",
    "print('Confusion Matrix: ',metrics.confusion_matrix(y_test,y_pred), sep = '\\n')\n",
    "\n",
    "#Accuracy using SVM Model\n",
    "SVM = LinearSVC()\n",
    "SVM.fit(X_train_dtm, y_train)\n",
    "y_pred = SVM.predict(X_test_dtm)\n",
    "print('\\nSupport Vector Machine')\n",
    "print('Accuracy Score: ',metrics.accuracy_score(y_test,y_pred)*100,'%',sep='')\n",
    "print('Confusion Matrix: ',metrics.confusion_matrix(y_test,y_pred), sep = '\\n')\n",
    "\n",
    "#Accuracy using KNN Model\n",
    "KNN = KNeighborsClassifier(n_neighbors = 3)\n",
    "KNN.fit(X_train_dtm, y_train)\n",
    "y_pred = KNN.predict(X_test_dtm)\n",
    "print('\\nK Nearest Neighbors (NN = 3)')\n",
    "print('Accuracy Score: ',metrics.accuracy_score(y_test,y_pred)*100,'%',sep='')\n",
    "print('Confusion Matrix: ',metrics.confusion_matrix(y_test,y_pred), sep = '\\n')\n",
    "\n",
    "#Naive Bayes Analysis\n",
    "tokens_words = vect.get_feature_names_out()\n",
    "print('\\nAnalysis')\n",
    "print('No. of tokens: ',len(tokens_words))\n",
    "counts = NB.feature_count_\n",
    "df_table = {'Token':tokens_words,'Negative': counts[0,:],'Positive': counts[1,:]}\n",
    "tokens = pd.DataFrame(df_table, columns= ['Token','Positive','Negative'])\n",
    "positives = len(tokens[tokens['Positive']>tokens['Negative']])\n",
    "print('No. of positive tokens: ',positives)\n",
    "print('No. of negative tokens: ',len(tokens_words)-positives)\n",
    "#Check positivity/negativity of specific tokens\n",
    "token_search = ['awesome']\n",
    "print('\\nSearch Results for token/s:',token_search)\n",
    "print(tokens.loc[tokens['Token'].isin(token_search)])\n",
    "#Analyse False Negatives (Actual: 1; Predicted: 0)(Predicted negative review for a positive review) \n",
    "print(X_test[ y_pred < y_test ])\n",
    "#Analyse False Positives (Actual: 0; Predicted: 1)(Predicted positive review for a negative review) \n",
    "print(X_test[ y_pred > y_test ])\n",
    "\n",
    "#Custom Test: Test a review on the best performing model (Logistic Regression)\n",
    "trainingVector = CountVectorizer(stop_words='english', ngram_range = (1,1), max_df = .80, min_df = 5)\n",
    "trainingVector.fit(X)\n",
    "X_dtm = trainingVector.transform(X)\n",
    "LR_complete = LogisticRegression()\n",
    "LR_complete.fit(X_dtm, y)\n",
    "#Input Review\n",
    "print('\\nTest a custom review message')\n",
    "print('Enter review to be analysed: ', end=\" \")\n",
    "test = []\n",
    "test.append(input())\n",
    "test_dtm = trainingVector.transform(test)\n",
    "predLabel = LR_complete.predict(test_dtm)\n",
    "tags = ['Negative','Positive']\n",
    "#Display Output\n",
    "print('The review is predicted',tags[predLabel[0]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
